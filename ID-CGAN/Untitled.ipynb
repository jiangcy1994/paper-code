{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate, Input, Lambda\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Conv2D)                 (None, 256, 256, 8)  216         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer2/lrelu (LeakyReLU)        (None, 256, 256, 8)  0           layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer2/conv (Conv2D)            (None, 256, 256, 8)  576         layer2/lrelu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer2/bn (BatchNormalization)  (None, 256, 256, 8)  32          layer2/conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer3/lrelu (LeakyReLU)        (None, 256, 256, 8)  0           layer2/bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer3/conv (Conv2D)            (None, 256, 256, 8)  576         layer3/lrelu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer3/bn (BatchNormalization)  (None, 256, 256, 8)  32          layer3/conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer4/lrelu (LeakyReLU)        (None, 256, 256, 8)  0           layer3/bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer4/conv (Conv2D)            (None, 256, 256, 8)  576         layer4/lrelu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer4/bn (BatchNormalization)  (None, 256, 256, 8)  32          layer4/conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer5/lrelu (LeakyReLU)        (None, 256, 256, 8)  0           layer4/bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer5/conv (Conv2D)            (None, 256, 256, 4)  288         layer5/lrelu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer5/bn (BatchNormalization)  (None, 256, 256, 4)  16          layer5/conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer6/lrelu (LeakyReLU)        (None, 256, 256, 4)  0           layer5/bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer6/conv (Conv2D)            (None, 256, 256, 1)  36          layer6/lrelu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer6/bn (BatchNormalization)  (None, 256, 256, 1)  4           layer6/conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dlayer6/relu (ReLU)             (None, 256, 256, 1)  0           layer6/bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dlayer6/tconv (Conv2DTranspose) (None, 256, 256, 4)  36          dlayer6/relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dlayer6/dropout (Dropout)       (None, 256, 256, 4)  0           dlayer6/tconv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dlayer5/relu (ReLU)             (None, 256, 256, 4)  0           dlayer6/dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dlayer5/tconv (Conv2DTranspose) (None, 256, 256, 8)  288         dlayer5/relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dlayer5/bn (BatchNormalization) (None, 256, 256, 8)  32          dlayer5/tconv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256, 256, 8)  0           dlayer5/bn[0][0]                 \n",
      "                                                                 layer4/bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dlayer4/relu (ReLU)             (None, 256, 256, 8)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dlayer4/tconv (Conv2DTranspose) (None, 256, 256, 8)  576         dlayer4/relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dlayer4/bn (BatchNormalization) (None, 256, 256, 8)  32          dlayer4/tconv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dlayer3/relu (ReLU)             (None, 256, 256, 8)  0           dlayer4/bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dlayer3/tconv (Conv2DTranspose) (None, 256, 256, 8)  576         dlayer3/relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dlayer3/bn (BatchNormalization) (None, 256, 256, 8)  32          dlayer3/tconv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256, 256, 8)  0           dlayer3/bn[0][0]                 \n",
      "                                                                 layer2/bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dlayer2/relu (ReLU)             (None, 256, 256, 8)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dlayer2/tconv (Conv2DTranspose) (None, 256, 256, 8)  576         dlayer2/relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dlayer2/bn (BatchNormalization) (None, 256, 256, 8)  32          dlayer2/tconv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dlayer1/relu (ReLU)             (None, 256, 256, 8)  0           dlayer2/bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dlayer1/tconv (Conv2DTranspose) (None, 256, 256, 3)  216         dlayer1/relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dlayer1.tanh (Activation)       (None, 256, 256, 3)  0           dlayer1/tconv[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,780\n",
      "Trainable params: 4,658\n",
      "Non-trainable params: 122\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
