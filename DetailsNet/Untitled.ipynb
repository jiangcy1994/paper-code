{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Add, BatchNormalization, Concatenate, Conv2D, Input, ReLU\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from GuidedFilter import guided_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature = 16             # number of feature maps\n",
    "num_channels = 3             # number of input's channels \n",
    "patch_size = 64              # patch size \n",
    "KernelSize = 3               # kernel size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1          # learning rate\n",
    "iterations = int(6e4)        # iterations\n",
    "batch_size = 20              # batch size\n",
    "save_model_path = \"./model/\" # saved model's path\n",
    "model_name = 'model-epoch'   # saved model's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(images, base):\n",
    "    base = guided_filter(images, images, 15, 1, nhwc=True) # using guided filter for obtaining base layer\n",
    "    detail = images - base   # detail layer\n",
    "    return detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetailsNet(images, is_training):\n",
    "    initializer = glorot_uniform()\n",
    "    regularizer = l2(1e-10)\n",
    "    \n",
    "    conv2d = lambda layer_id: Conv2D(filters=num_feature, kernel_size=KernelSize, padding='same', \n",
    "                                     kernel_initializer=initializer, kernel_regularizer=regularizer,\n",
    "                                     name='layer_%d/conv_%d' % (layer_id, layer_id))\n",
    "    bn = lambda layer_id: BatchNormalization(name='layer_%d/bn_%d' % (layer_id, layer_id))\n",
    "    relu = lambda layer_id: ReLU(name='layer_%d/relu_%d' % (layer_id, layer_id))\n",
    "    \n",
    "    inp = Input((images, images, num_channels))\n",
    "    \n",
    "    \n",
    "    base = guided_filter(inp, inp, 15, 1, nhwc=True) # using guided filter for obtaining base layer\n",
    "    detail = images - base   # detail layer\n",
    "    \n",
    "    output = conv2d(1)(detail)\n",
    "    output = bn(1)(output, training=is_training)\n",
    "    output_shortcut = relu(1)(output)\n",
    "    \n",
    "    #  layers 2 to 25\n",
    "    for i in range(12):\n",
    "        layer_id = i * 2 + 2\n",
    "        output = conv2d(layer_id)(output_shortcut)\n",
    "        output = bn(layer_id)(output, training=is_training)\n",
    "        output = relu(layer_id)(output)\n",
    "\n",
    "        layer_id = i * 2 + 3\n",
    "        output = conv2d(layer_id)(output)\n",
    "        output = bn(layer_id)(output, training=is_training)\n",
    "        output = relu(layer_id)(output)\n",
    "\n",
    "        output_shortcut = Add(name='add_%d'%i)([output_shortcut, output])\n",
    "\n",
    "    # layer 26\n",
    "    output = Conv2D(filters=num_channels, kernel_size=KernelSize, padding='same', \n",
    "                    kernel_initializer=initializer, kernel_regularizer=regularizer,\n",
    "                    name='layer_26/conv_26')(output_shortcut)\n",
    "    neg_residual = bn(26)(output, training=is_training)\n",
    "    \n",
    "    final_out = Add(name='add_final')([inp, neg_residual])\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[final_out])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_1/conv_1 (Conv2D)         (None, 256, 256, 16) 448         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_1/bn_1 (BatchNormalizatio (None, 256, 256, 16) 64          layer_1/conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_1/relu_1 (ReLU)           (None, 256, 256, 16) 0           layer_1/bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_2/conv_2 (Conv2D)         (None, 256, 256, 16) 2320        layer_1/relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_2/bn_2 (BatchNormalizatio (None, 256, 256, 16) 64          layer_2/conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_2/relu_2 (ReLU)           (None, 256, 256, 16) 0           layer_2/bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_3/conv_3 (Conv2D)         (None, 256, 256, 16) 2320        layer_2/relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_3/bn_3 (BatchNormalizatio (None, 256, 256, 16) 64          layer_3/conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_3/relu_3 (ReLU)           (None, 256, 256, 16) 0           layer_3/bn_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_0 (Add)                     (None, 256, 256, 16) 0           layer_1/relu_1[0][0]             \n",
      "                                                                 layer_3/relu_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_4/conv_4 (Conv2D)         (None, 256, 256, 16) 2320        add_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_4/bn_4 (BatchNormalizatio (None, 256, 256, 16) 64          layer_4/conv_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_4/relu_4 (ReLU)           (None, 256, 256, 16) 0           layer_4/bn_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_5/conv_5 (Conv2D)         (None, 256, 256, 16) 2320        layer_4/relu_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_5/bn_5 (BatchNormalizatio (None, 256, 256, 16) 64          layer_5/conv_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_5/relu_5 (ReLU)           (None, 256, 256, 16) 0           layer_5/bn_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256, 256, 16) 0           add_0[0][0]                      \n",
      "                                                                 layer_5/relu_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_6/conv_6 (Conv2D)         (None, 256, 256, 16) 2320        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_6/bn_6 (BatchNormalizatio (None, 256, 256, 16) 64          layer_6/conv_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_6/relu_6 (ReLU)           (None, 256, 256, 16) 0           layer_6/bn_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_7/conv_7 (Conv2D)         (None, 256, 256, 16) 2320        layer_6/relu_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_7/bn_7 (BatchNormalizatio (None, 256, 256, 16) 64          layer_7/conv_7[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_7/relu_7 (ReLU)           (None, 256, 256, 16) 0           layer_7/bn_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 16) 0           add_1[0][0]                      \n",
      "                                                                 layer_7/relu_7[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_8/conv_8 (Conv2D)         (None, 256, 256, 16) 2320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_8/bn_8 (BatchNormalizatio (None, 256, 256, 16) 64          layer_8/conv_8[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_8/relu_8 (ReLU)           (None, 256, 256, 16) 0           layer_8/bn_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_9/conv_9 (Conv2D)         (None, 256, 256, 16) 2320        layer_8/relu_8[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_9/bn_9 (BatchNormalizatio (None, 256, 256, 16) 64          layer_9/conv_9[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_9/relu_9 (ReLU)           (None, 256, 256, 16) 0           layer_9/bn_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256, 256, 16) 0           add_2[0][0]                      \n",
      "                                                                 layer_9/relu_9[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_10/conv_10 (Conv2D)       (None, 256, 256, 16) 2320        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_10/bn_10 (BatchNormalizat (None, 256, 256, 16) 64          layer_10/conv_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_10/relu_10 (ReLU)         (None, 256, 256, 16) 0           layer_10/bn_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_11/conv_11 (Conv2D)       (None, 256, 256, 16) 2320        layer_10/relu_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_11/bn_11 (BatchNormalizat (None, 256, 256, 16) 64          layer_11/conv_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_11/relu_11 (ReLU)         (None, 256, 256, 16) 0           layer_11/bn_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256, 256, 16) 0           add_3[0][0]                      \n",
      "                                                                 layer_11/relu_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_12/conv_12 (Conv2D)       (None, 256, 256, 16) 2320        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_12/bn_12 (BatchNormalizat (None, 256, 256, 16) 64          layer_12/conv_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_12/relu_12 (ReLU)         (None, 256, 256, 16) 0           layer_12/bn_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_13/conv_13 (Conv2D)       (None, 256, 256, 16) 2320        layer_12/relu_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_13/bn_13 (BatchNormalizat (None, 256, 256, 16) 64          layer_13/conv_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_13/relu_13 (ReLU)         (None, 256, 256, 16) 0           layer_13/bn_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 256, 16) 0           add_4[0][0]                      \n",
      "                                                                 layer_13/relu_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_14/conv_14 (Conv2D)       (None, 256, 256, 16) 2320        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_14/bn_14 (BatchNormalizat (None, 256, 256, 16) 64          layer_14/conv_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_14/relu_14 (ReLU)         (None, 256, 256, 16) 0           layer_14/bn_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_15/conv_15 (Conv2D)       (None, 256, 256, 16) 2320        layer_14/relu_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_15/bn_15 (BatchNormalizat (None, 256, 256, 16) 64          layer_15/conv_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_15/relu_15 (ReLU)         (None, 256, 256, 16) 0           layer_15/bn_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 256, 16) 0           add_5[0][0]                      \n",
      "                                                                 layer_15/relu_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_16/conv_16 (Conv2D)       (None, 256, 256, 16) 2320        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_16/bn_16 (BatchNormalizat (None, 256, 256, 16) 64          layer_16/conv_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_16/relu_16 (ReLU)         (None, 256, 256, 16) 0           layer_16/bn_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_17/conv_17 (Conv2D)       (None, 256, 256, 16) 2320        layer_16/relu_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_17/bn_17 (BatchNormalizat (None, 256, 256, 16) 64          layer_17/conv_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_17/relu_17 (ReLU)         (None, 256, 256, 16) 0           layer_17/bn_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256, 256, 16) 0           add_6[0][0]                      \n",
      "                                                                 layer_17/relu_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_18/conv_18 (Conv2D)       (None, 256, 256, 16) 2320        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_18/bn_18 (BatchNormalizat (None, 256, 256, 16) 64          layer_18/conv_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_18/relu_18 (ReLU)         (None, 256, 256, 16) 0           layer_18/bn_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_19/conv_19 (Conv2D)       (None, 256, 256, 16) 2320        layer_18/relu_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_19/bn_19 (BatchNormalizat (None, 256, 256, 16) 64          layer_19/conv_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_19/relu_19 (ReLU)         (None, 256, 256, 16) 0           layer_19/bn_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256, 256, 16) 0           add_7[0][0]                      \n",
      "                                                                 layer_19/relu_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_20/conv_20 (Conv2D)       (None, 256, 256, 16) 2320        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_20/bn_20 (BatchNormalizat (None, 256, 256, 16) 64          layer_20/conv_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_20/relu_20 (ReLU)         (None, 256, 256, 16) 0           layer_20/bn_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_21/conv_21 (Conv2D)       (None, 256, 256, 16) 2320        layer_20/relu_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_21/bn_21 (BatchNormalizat (None, 256, 256, 16) 64          layer_21/conv_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_21/relu_21 (ReLU)         (None, 256, 256, 16) 0           layer_21/bn_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 256, 256, 16) 0           add_8[0][0]                      \n",
      "                                                                 layer_21/relu_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_22/conv_22 (Conv2D)       (None, 256, 256, 16) 2320        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_22/bn_22 (BatchNormalizat (None, 256, 256, 16) 64          layer_22/conv_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_22/relu_22 (ReLU)         (None, 256, 256, 16) 0           layer_22/bn_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_23/conv_23 (Conv2D)       (None, 256, 256, 16) 2320        layer_22/relu_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_23/bn_23 (BatchNormalizat (None, 256, 256, 16) 64          layer_23/conv_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_23/relu_23 (ReLU)         (None, 256, 256, 16) 0           layer_23/bn_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 256, 256, 16) 0           add_9[0][0]                      \n",
      "                                                                 layer_23/relu_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_24/conv_24 (Conv2D)       (None, 256, 256, 16) 2320        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_24/bn_24 (BatchNormalizat (None, 256, 256, 16) 64          layer_24/conv_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_24/relu_24 (ReLU)         (None, 256, 256, 16) 0           layer_24/bn_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_25/conv_25 (Conv2D)       (None, 256, 256, 16) 2320        layer_24/relu_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_25/bn_25 (BatchNormalizat (None, 256, 256, 16) 64          layer_25/conv_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_25/relu_25 (ReLU)         (None, 256, 256, 16) 0           layer_25/bn_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 256, 256, 16) 0           add_10[0][0]                     \n",
      "                                                                 layer_25/relu_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_26/conv_26 (Conv2D)       (None, 256, 256, 3)  435         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_26/bn_26 (BatchNormalizat (None, 256, 256, 3)  12          layer_26/conv_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_final (Add)                 (None, 256, 256, 3)  0           input_14[0][0]                   \n",
      "                                                                 layer_26/bn_26[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 58,175\n",
      "Trainable params: 57,369\n",
      "Non-trainable params: 806\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = inference(None, is_training=False)\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][-3:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(images, is_training):\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale = 1e-10)\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "\n",
    "    base = guided_filter(images, images, 15, 1, nhwc=True) # using guided filter for obtaining base layer\n",
    "    detail = images - base   # detail layer\n",
    "\n",
    "   #  layer 1\n",
    "    with tf.variable_scope('layer_1'):\t\n",
    "         output = tf.layers.conv2d(detail, num_feature, KernelSize, padding = 'same', kernel_initializer = initializer, \n",
    "                                   kernel_regularizer = regularizer, name='conv_1')\n",
    "         output = tf.layers.batch_normalization(output, training=is_training, name='bn_1')\n",
    "         output_shortcut = tf.nn.relu(output, name='relu_1')\n",
    "  \n",
    "   #  layers 2 to 25\n",
    "    for i in range(12):\n",
    "        with tf.variable_scope('layer_%d'%(i*2+2)):\t\n",
    "             output = tf.layers.conv2d(output_shortcut, num_feature, KernelSize, padding='same', kernel_initializer = initializer, \n",
    "                                       kernel_regularizer = regularizer, name=('conv_%d'%(i*2+2)))\n",
    "             output = tf.layers.batch_normalization(output, training=is_training, name=('bn_%d'%(i*2+2)))\t\n",
    "             output = tf.nn.relu(output, name=('relu_%d'%(i*2+2)))\n",
    "\n",
    "        with tf.variable_scope('layer_%d'%(i*2+3)): \n",
    "             output = tf.layers.conv2d(output, num_feature, KernelSize, padding='same', kernel_initializer = initializer,\n",
    "                                       kernel_regularizer = regularizer, name=('conv_%d'%(i*2+3)))\n",
    "             output = tf.layers.batch_normalization(output, training=is_training, name=('bn_%d'%(i*2+3)))\n",
    "             output = tf.nn.relu(output, name=('relu_%d'%(i*2+3)))\n",
    "\n",
    "        output_shortcut = tf.add(output_shortcut, output)\t# shortcut\n",
    "\n",
    "   # layer 26\n",
    "    with tf.variable_scope('layer_26'):\n",
    "         output = tf.layers.conv2d(output_shortcut, num_channels, KernelSize, padding='same',   kernel_initializer = initializer, \n",
    "                                   kernel_regularizer = regularizer, name='conv_26')\n",
    "         neg_residual = tf.layers.batch_normalization(output, training=is_training, name='bn_26')\n",
    "\t\t \n",
    "    final_out = tf.add(images, neg_residual)\n",
    "\t\n",
    "    return final_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
