{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sub_net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    \n",
    "    def __init__(self, img_shape=(128, 128, 3), g_filter=32, d_filter=64, lamdba_cycle=10.0, lambda_id=1.0):\n",
    "        # Input shape\n",
    "        self.img_rows, self.img_cols, self.channels = self.img_shape = img_shape\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.generator_filter, self.discriminator_filter = 32, 64\n",
    "\n",
    "        # Loss weights\n",
    "        self.lambda_cycle, self.lambda_id = lamdba_cycle, lambda_id\n",
    "\n",
    "#         optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminators\n",
    "        self.discriminator_A = self.build_discriminator()\n",
    "        self.discriminator_A.name = 'discriminator_A'\n",
    "        self.discriminator_A.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        self.discriminator_B = self.build_discriminator()\n",
    "        self.discriminator_B.name = 'discriminator_B'\n",
    "        self.discriminator_B.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generators\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generators\n",
    "        self.generator_A_to_B = self.build_generator()\n",
    "        self.generator_A_to_B.name = 'generator_A_to_B'\n",
    "        self.generator_B_to_A = self.build_generator()\n",
    "        self.generator_B_to_A.name = 'generator_B_to_A'\n",
    "\n",
    "        # Input images from both domains\n",
    "        img_A = Input(shape=self.img_shape, name='input_A')\n",
    "        img_B = Input(shape=self.img_shape, name='input_B')\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.generator_A_to_B(img_A)\n",
    "        fake_A = self.generator_B_to_A(img_B)\n",
    "        # Translate images back to original domain\n",
    "        reconstr_A = self.generator_B_to_A(fake_B)\n",
    "        reconstr_B = self.generator_A_to_B(fake_A)\n",
    "        # Identity mapping of images\n",
    "        img_A_id = self.generator_B_to_A(img_A)\n",
    "        img_B_id = self.generator_A_to_B(img_B)\n",
    "\n",
    "        # For the combined model we will only train the generators\n",
    "        self.discriminator_A.trainable = False\n",
    "        self.discriminator_B.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images\n",
    "        valid_A = self.discriminator_A(fake_A)\n",
    "        valid_B = self.discriminator_B(fake_B)\n",
    "\n",
    "        # Combined model trains generators to fool discriminators\n",
    "        self.combined = Model(inputs=[img_A, img_B],\n",
    "                              outputs=[valid_A, valid_B,\n",
    "                                       reconstr_A, reconstr_B,\n",
    "                                       img_A_id, img_B_id ])\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                            loss_weights=[1, 1,\n",
    "                                          self.lambda_cycle, self.lambda_cycle,\n",
    "                                          self.lambda_id, self.lambda_id ],\n",
    "                            optimizer='rmsprop')\n",
    "    \n",
    "  \n",
    "    def build_generator(self):\n",
    "        return UNET_G(self.img_rows, num_generator_filter=self.generator_filter)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        return BASIC_D(self.channels, self.discriminator_filter)\n",
    "    \n",
    "    def train(self, dataloader, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(data_loader.load_batch(batch_size)):\n",
    "\n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "\n",
    "                # Translate images to opposite domain\n",
    "                fake_B = self.g_AB.predict(imgs_A)\n",
    "                fake_A = self.g_BA.predict(imgs_B)\n",
    "\n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = self.discriminator_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = self.discriminator_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "                dB_loss_real = self.discriminator_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = self.discriminator_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "                # Total disciminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "\n",
    "                # ------------------\n",
    "                #  Train Generators\n",
    "                # ------------------\n",
    "\n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
    "                                                      [valid, valid,\n",
    "                                                       imgs_A, imgs_B,\n",
    "                                                       imgs_A, imgs_B])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "                # Plot the progress\n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
    "                                                                        % ( epoch, epochs,\n",
    "                                                                            batch_i, self.data_loader.n_batches,\n",
    "                                                                            d_loss[0], 100*d_loss[1],\n",
    "                                                                            g_loss[0],\n",
    "                                                                            np.mean(g_loss[1:3]),\n",
    "                                                                            np.mean(g_loss[3:5]),\n",
    "                                                                            np.mean(g_loss[5:6]),\n",
    "                                                                            elapsed_time))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)\n",
    "    \n",
    "     def sample_images(self, epoch, batch_i):\n",
    "        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n",
    "        r, c = 2, 3\n",
    "\n",
    "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
    "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
    "\n",
    "        # Demo (for GIF)\n",
    "        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
    "        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB.predict(imgs_A)\n",
    "        fake_A = self.g_BA.predict(imgs_B)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CycleGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_30 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_B_to_A (Model)        (None, 128, 128, 3)  10465699    input_30[0][0]                   \n",
      "                                                                 generator_A_to_B[1][0]           \n",
      "                                                                 input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "generator_A_to_B (Model)        (None, 128, 128, 3)  10465699    input_29[0][0]                   \n",
      "                                                                 generator_B_to_A[1][0]           \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "discriminator_A (Model)         multiple             2767425     generator_B_to_A[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "discriminator_B (Model)         multiple             2767425     generator_A_to_B[1][0]           \n",
      "==================================================================================================\n",
      "Total params: 26,466,248\n",
      "Trainable params: 20,923,590\n",
      "Non-trainable params: 5,542,658\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.combined.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
